{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "#This gives python access to all the TensorFlow's classes, methods and symbols\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "===\n",
    "* The higher level APIs are built on top of TensorFlow Core.\n",
    "* Central Unit in TensorFlow is a Tensor. Array of any number of dimensions (ranks)\n",
    "* A TensorFlow graph is a series of TensorFlow operations arranged into a graph of nodes\n",
    "* A Node takes zero or more tensors as input and outputs another tensor\n",
    "* To actually evaluate nodes (produce their ouput) we must run the computational graph within a session\n",
    "* Operations are also nodes\n",
    "* Tensorboard can display a picture of the computational graph\n",
    "* A graph can be parameterized to accept external inputs\n",
    "* Placeholder: accept external inputs (later)\n",
    "* Variables are not initialized when you call tf.Variable. To initialize all the varibles in a TensorFlow program, you must explicitly call tf.global_variables_initializer()\n",
    "* A loss function measure how far apart the current model is from the provided data.\n",
    "* A variable is initialized to the value provided to tf.Variable but can be changed using operations like tf.assign\n",
    "* Optimizer: Technique to slowly change each variables in order to minimize the loss function\n",
    "* tf.estimator: High Level TensorFlow library that simplifies the mechanics of machine learning including the following:\n",
    "    * running training loops\n",
    "    * running evaluation loops\n",
    "    * managing data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Nodes\n",
    "node1 = tf.constant(3.0, dtype=tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "print(node1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(node1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3:  Tensor(\"Add_1:0\", shape=(), dtype=float32)\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3)\n",
    "print(sess.run(node3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b # + is shorcut for tf.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n"
     ]
    }
   ],
   "source": [
    "#Here we feed values into the place holders\n",
    "print(sess.run(adder_node, {a:3, b:4.5})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3\n",
    "print(sess.run(add_and_triple, {a: 3, b: 4.5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, {x: [1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1,2,3,4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.]) #Why do we need to store it into fixW?\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1,2,3,4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.train API**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01) #Learning rate\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) #reset values to incorrect defaults\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainable Linear Regression Model (Low Level)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: -0.999998, b: 0.999993, loss: 3.18785e-11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#Model Parameter y = Wx + b\n",
    "W = tf.Variable(.3, dtype = tf.float32)\n",
    "b = tf.Variable(.1, dtype = tf.float32)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "#Model Input and output y = Wx + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b\n",
    "\n",
    "#loss\n",
    "squared_deltas = tf.square(linear_model - y) \n",
    "loss = tf.reduce_sum(squared_deltas) #sum of the squares\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "#training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "\n",
    "#training loop\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) #Initialized all variables to default\n",
    "    for i in range(1000): #cycles\n",
    "        sess.run(train, {x: x_train, y: y_train})\n",
    "        \n",
    "    #evaluate training accuracy\n",
    "    curr_W, curr_b, curr_loss = sess.run([W,b,loss], {x:x_train, y: y_train})\n",
    "    print(\"W: %s, b: %s, loss: %s\"%(curr_W, curr_b, curr_loss))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is very small number (close to zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trainable Linear Regression Model (Estimator: High Level)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\avour\\AppData\\Local\\Temp\\tmpcfvakvzt\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\avour\\\\AppData\\\\Local\\\\Temp\\\\tmpcfvakvzt', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D4A3148F28>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\avour\\AppData\\Local\\Temp\\tmpcfvakvzt\\model.ckpt.\n",
      "INFO:tensorflow:loss = 19.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 859.769\n",
      "INFO:tensorflow:loss = 0.115248, step = 101 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 1028.19\n",
      "INFO:tensorflow:loss = 0.0502527, step = 201 (0.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.992\n",
      "INFO:tensorflow:loss = 0.00937547, step = 301 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 898.509\n",
      "INFO:tensorflow:loss = 0.000675106, step = 401 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 949.849\n",
      "INFO:tensorflow:loss = 0.000975452, step = 501 (0.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 906.669\n",
      "INFO:tensorflow:loss = 0.000228339, step = 601 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 906.679\n",
      "INFO:tensorflow:loss = 6.5847e-05, step = 701 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 940.891\n",
      "INFO:tensorflow:loss = 6.20034e-06, step = 801 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 898.496\n",
      "INFO:tensorflow:loss = 2.5123e-06, step = 901 (0.115 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\avour\\AppData\\Local\\Temp\\tmpcfvakvzt\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.14366e-07.\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-10-03:08:02\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\avour\\AppData\\Local\\Temp\\tmpcfvakvzt\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-10-03:08:02\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.50628e-07, global_step = 1000, loss = 6.02513e-07\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-10-03:08:03\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\avour\\AppData\\Local\\Temp\\tmpcfvakvzt\\model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-10-03:08:04\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00255687, global_step = 1000, loss = 0.0102275\n",
      "train metrics: {'average_loss': 1.5062825e-07, 'loss': 6.0251301e-07, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025568712, 'loss': 0.010227485, 'global_step': 1000}\n",
      "\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\avour\\AppData\\Local\\Temp\\tmpcfvakvzt\\model.ckpt-1000\n",
      "{'predictions': array([-0.0006302], dtype=float32)}\n",
      "{'predictions': array([-1.00030994], dtype=float32)}\n",
      "{'predictions': array([-1.99998975], dtype=float32)}\n",
      "{'predictions': array([-2.99966955], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation (inference)\n",
    "# There are many predefined types like linear regression, linear classification, and\n",
    "# many neural networks classifiers and regressors.\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# We have to tell the function how many batches of data (num_epochs)\n",
    "# we want and how big each batch should be\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1, -2, -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "x_test = np.array([1., 2., 3., 4.])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=True)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_test}, y= None, batch_size=4, num_epochs=1, shuffle=False)\n",
    "\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the method and passing the\n",
    "# training dataset\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "test_predict = estimator.predict(input_fn=test_input_fn)\n",
    "\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n",
    "print(\"\\n\")\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "for i in test_predict:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
